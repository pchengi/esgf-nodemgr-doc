\documentclass[oneside,12pt]{memoir}
\def\mychaplineone{Developer notes for}
\def\mychaplinetwo{ESGF Node Manager}
%\def\mychaplinethree{And Some More...}
\def\myauthone{Prashanth Dwarakanath}
\def\myauthtwo{Sasha Ames}
%\def\myauththree{Torgny Fax\'en}
\def\mypress{Earth Sciences Grid Federation}
\usepackage{chengi}
\usepackage{biblatex}
\bibliography{thebib}
\DefineBibliographyStrings{english}{%
  bibliography = {References},
}
\def\phname{NM{ }}
\def\vernum{December 5, 2014}
\setcounter{tocdepth}{2}
\thispagestyle{empty}
\titleGM
\chapterstyle{BlueBox}
\pagestyle{mystyle}
\begin{document}
\frontmatter
\hypertarget{mytocmarker}
\tableofcontents
\mainmatter
\setcounter{secnumdepth}{2}
\chapter{Solution Design}
\section{Overview}


\section{Design Considerations}

We are interested in a hierarchical framework for node management rather than a pure p2p.  In this case nodes elect "super-nodes" that perform additional tasks than "member-nodes".  Our goal for scalability is to have a balance of super vs member nodes to ensure that no super-node becomes oversubscribed.  Super-nodes operate at the "project" level.   

A node that serves as the "super-node" for project A can be a member node for project B.  Super-nodes can serve in that role for multiple projects.    Configuring a node for eligibility for selection to become a super node is voluntary, but important for the federation to have an "adequate" number of candidates.

Vetting for a super node. Hand-picked initial super-nodes.  

member nodes pass messages.  

Node manager admin interface.  Allow admins to eg. sign certs, vet nodes,  

\begin{enumerate}
\item
Tree-based communication between super nodes and member nodes to reduce communication overheads, ie. avoid $n^2$ patterns.  We expect a ``wide'' tree with ``few" hops.
\item 
Need to maintain backward compatibility with format of registration.xml etc, to not break existing parsers. 
\end{enumerate}


\section{Breakup of tasks}
\subsection{zookeeper evaluation}
\begin{enumerate}
\item
Performance evaluation
\item
Evaluate functionality
\item
Assess  API
\end{enumerate}

\subsection{metrics gathering}
\begin{enumerate}
\item Gather needed metrics
\item design SQL queries
\item  implement result aggregation
\end{enumerate}



\section{System Architecture}
\begin{center}
\includegraphics[width=5in]{presentation/NM-design.pdf}
\end{center}

\subsection{Components}
We see two major components in this solution.
\begin{enumerate}
\item 
A component which takes care of failure detection, failure handling, leader election, shared state etc.
Apache ZooKeeper seems to be a very promising fit for this role, so this component shall henceforth simply be refered to as ZooKeeper.
\item
A component that serves as a `feeder', to the zookeeper. This would also provide an administrative interface to the node manager. This is the component of the node manager that is meant to be exposed to the federation, and not the ZooKeeper itself, and it includes the ESGF Node Manager API. Henceforth, this component shall simply be refered to as the node manager. The node manager will also be used by local admins, to generate requests for federation membership or certificate signing and allow supernode admins to ratify/sign these requests. The node manager would also be responsible for collection of metrics.
\end{enumerate}

\subsection{Metric subcomponent}

This subcomponent produces the metrics that appear on the dashboard or other UI.  Some metrics are based on node state managed by the "feeder" service.  The zookeeper DFS can be used as the metastore for metric metadata.  Much metric "raw" data will be found in the log files.  A crawler procedure can gather stats from the logs.   The metric service can include aggregate information from the provenance collection system. \yellowline{Also, the currently built-in hooks to log realtime download activity etc would have to be refined to ensure greater accuracy and eliminate problems such as false positives/negatives.}



An optional part of this is a centralized collection of the log data that can be queried efficiently.  We expect that this would be on data center supernodes.   
\subsection{Self-check subcomponent}
This is a subcomponent of the node manager which is responsible for carrying out sanity checks at regular intervals, on itself. When it fails the sanity checks, it contacts the local node manager to flag itself ineligible to continue as a supernode/standby supernode/member node. When the node passes a subsequent sanity check, the self-check component contacts the local node manager, to flag itself ready for resumption of duties.  The self-check subcomponent would also use the messaging subcomponent, to send out alert notifications to the local admin, when sanity checks fail.

\subsection{Messaging subcomponent}
The messaging subcomponent is used by the self-check subcomponent, to alert the local admin, when the state of the node changes, i.e. fails a sanity check, or clears one, after having been flagged down by previous checks.



\section{Node manager capacities}
Each and every ESGF installation, irrespective of role, i.e. data, compute etc, would have the node manager as a component.  However, the node manager itself can function in different capacities. 
\begin{enumerate}
\item \textbf{Membernode}: This is the default capacity of a node manager. It cannot query other node manager instances and can only pass on validated messages. See Section~\ref{commcases} for more. A membernode can volunteer to be a supernode or a standby supernode.
\item \textbf{Supernode}: This is a membernode which volunteered to function as a supernode and was vetted Responsible for querying nodes which it is responsible for.  A federation would have multiple supernodes which divide the workload among themselves. Supernodes also perform aggregation of gathered metrics. 
\item \textbf{Standby supernode}: A standby supernode is a membernode which volunteered to function as a supernode when the number of supernodes in the federation falls below a predefined threshold. These nodes temporarily function as supernodes and return to being standy supernodes, when the supernode count stabilizes in the federation.
\end{enumerate}

\section{Communication use-cases}
\label{commcases}
A bulk of internode communication is handled implicitly by ZooKeeper, releasing us from having to explicitly establish communication for tasks such as leader election, but the ZooKeeper is not exposed to the outside world. Instead, it is controlled/accessed with the node manager, which serves as both a controller for ZooKeeper itself, and also as a wrapper for ZooKeeper. This would need node manager instances to communicate with each other. Let's consider the types of communication between node manager instances.
\begin{enumerate}
\item \textbf{Supernode to membernode}: metric queries, status queries, status change notifcation (standby to supernode, viceversa etc)
\item \textbf{Supernode to supernode}: Shoot the node in the head, in case of malfunction
\item \textbf{Membernode to membernode}: passing on authenticated messages received from supernodes.  (this is implicit in zookeeper's communication) 
\item \textbf{Membernode to supernode}: Pushing local config status etc.
\end{enumerate}

\begin{center}
\includegraphics[width=5in]{presentation/ESG-node-org.pdf}
\end{center}


\section{Authentication mechanisms}
Distinction to be made between user authentication and system authentication, as certain privileged operations may need to be executed without human intervention. This would need a system or process to be authorized to perform the operation. 
\section{Issues and questions}
This is to be a place to list out problems that need to be handled.
\begin{enumerate}
\item
do we use zookeeper?

to what extent can we rely if we do,  what do we need to implement for the nm


Is zookeeper a fit for management?
\item
can zookeeper manage group-level access control?  We think it can.  Need to evaluate.
\item
Is zookeeper python API adequate

\item
Deal with "spoofed" node; ensure relayed information is legitimate. 
\item
%Need to choose centralized query service database system.  Use Hadoop, spark, Hive, Cassandra, or some RDBMS?
Need the supernode to query nodes for metrics and perform aggregation where necessary.

\end{enumerate}
\section{To revisit}
\begin{enumerate}
\item Support for automated replication of datasets
\end{enumerate}
%\nocite{KandR}
\printbibliography
\hypertarget{mymarker}{}
\printindex
\end{document}
